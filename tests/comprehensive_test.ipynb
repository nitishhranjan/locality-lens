{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Locality Lens - Comprehensive Test Suite\n",
        "\n",
        "This notebook tests the complete Locality Lens workflow with:\n",
        "- Basic functionality tests\n",
        "- Parallel execution verification\n",
        "- Different user profiles\n",
        "- Edge cases\n",
        "- Performance benchmarks\n",
        "- State inspection\n",
        "\n",
        "## ‚ö†Ô∏è Important Notes:\n",
        "\n",
        "1. **Markdown cells** (like this one) are for documentation only - they cannot be executed. Only run Python code cells.\n",
        "2. **Run cells in order** - Start with Cell 2 (Setup and Imports) first, then run other cells sequentially.\n",
        "3. **Working directory** - The notebook automatically detects if you're running from `tests/` or project root.\n",
        "4. **If you get import errors**, make sure you've installed dependencies: `pip install -r requirements.txt`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Imports successful!\n",
            "üìÅ Project root: /Users/nitish.ranjan/Documents/AiDash/Educational/research/locality-lens\n",
            "üìÅ Current dir: /Users/nitish.ranjan/Documents/AiDash/Educational/research/locality-lens/tests\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "import time\n",
        "from pathlib import Path\n",
        "\n",
        "# Add project root to path\n",
        "# Handle both cases: running from tests/ or from project root\n",
        "current_dir = Path.cwd()\n",
        "if current_dir.name == 'tests':\n",
        "    project_root = current_dir.parent\n",
        "else:\n",
        "    project_root = current_dir\n",
        "\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "# Import required modules\n",
        "try:\n",
        "    from src.graph.graph import compile_graph\n",
        "    from src.graph.state import LocalityState\n",
        "    import json\n",
        "    from pprint import pprint\n",
        "    print(f\"‚úÖ Imports successful!\")\n",
        "    print(f\"üìÅ Project root: {project_root}\")\n",
        "    print(f\"üìÅ Current dir: {current_dir}\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Import error: {e}\")\n",
        "    print(f\"üìÅ Project root: {project_root}\")\n",
        "    print(f\"üìÅ Current dir: {current_dir}\")\n",
        "    print(f\"üìÅ Python path: {sys.path[:3]}\")\n",
        "    raise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_initial_state(\n",
        "    user_input: str,\n",
        "    user_profile: str = None\n",
        "):\n",
        "    \"\"\"Create initial state for testing.\"\"\"\n",
        "    return {\n",
        "        \"user_input\": user_input,\n",
        "        \"user_profile\": user_profile,\n",
        "        \"coordinates\": None,\n",
        "        \"address\": None,\n",
        "        \"osm_data\": {},\n",
        "        \"aqi_data\": None,\n",
        "        \"selected_metrics\": [],\n",
        "        \"statistics\": {},\n",
        "        \"user_intent\": {},\n",
        "        \"summary\": None,\n",
        "        \"recommendations\": [],\n",
        "        \"visualization_data\": None,\n",
        "        \"errors\": [],\n",
        "        \"warnings\": [],\n",
        "        \"next_action\": \"\",\n",
        "        \"processing_steps\": []\n",
        "    }\n",
        "\n",
        "\n",
        "def run_test(graph, state, test_name: str) -> dict:\n",
        "    \"\"\"Run a test and return results with timing.\"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"TEST: {test_name}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    try:\n",
        "        # Run graph with streaming to track progress\n",
        "        events = []\n",
        "        for event in graph.stream(state, stream_mode=\"updates\"):\n",
        "            events.append(event)\n",
        "            for node_name, node_state in event.items():\n",
        "                if isinstance(node_state, dict):\n",
        "                    steps = node_state.get(\"processing_steps\", [])\n",
        "                    if steps:\n",
        "                        print(f\"  ‚úì {node_name}: {steps[-1]}\")\n",
        "        \n",
        "        # Get final state\n",
        "        final_state = graph.invoke(state)\n",
        "        \n",
        "        elapsed = time.time() - start_time\n",
        "        \n",
        "        return {\n",
        "            \"success\": True,\n",
        "            \"elapsed_time\": elapsed,\n",
        "            \"final_state\": final_state,\n",
        "            \"events\": events,\n",
        "            \"errors\": final_state.get(\"errors\", []),\n",
        "            \"warnings\": final_state.get(\"warnings\", [])\n",
        "        }\n",
        "    except Exception as e:\n",
        "        elapsed = time.time() - start_time\n",
        "        return {\n",
        "            \"success\": False,\n",
        "            \"elapsed_time\": elapsed,\n",
        "            \"error\": str(e),\n",
        "            \"final_state\": None\n",
        "        }\n",
        "\n",
        "\n",
        "def print_test_results(result: dict, verbose: bool = False):\n",
        "    \"\"\"Print test results in a formatted way.\"\"\"\n",
        "    if result[\"success\"]:\n",
        "        print(f\"\\n‚úÖ TEST PASSED\")\n",
        "        print(f\"‚è±Ô∏è  Time: {result['elapsed_time']:.2f}s\")\n",
        "        \n",
        "        if result.get(\"errors\"):\n",
        "            print(f\"\\n‚ö†Ô∏è  Errors: {len(result['errors'])}\")\n",
        "            for error in result[\"errors\"]:\n",
        "                print(f\"   - {error}\")\n",
        "        \n",
        "        if result.get(\"warnings\"):\n",
        "            print(f\"\\n‚ö†Ô∏è  Warnings: {len(result['warnings'])}\")\n",
        "            for warning in result[\"warnings\"]:\n",
        "                print(f\"   - {warning}\")\n",
        "        \n",
        "        final_state = result[\"final_state\"]\n",
        "        \n",
        "        if verbose:\n",
        "            print(f\"\\nüìä Final State Summary:\")\n",
        "            print(f\"   - Coordinates: {final_state.get('coordinates')}\")\n",
        "            print(f\"   - Address: {final_state.get('address')}\")\n",
        "            print(f\"   - Selected Metrics: {len(final_state.get('selected_metrics', []))}\")\n",
        "            print(f\"   - Statistics Count: {len(final_state.get('statistics', {}))}\")\n",
        "            print(f\"   - Summary Generated: {final_state.get('summary') is not None}\")\n",
        "            print(f\"   - User Intent: {final_state.get('user_intent', {})}\")\n",
        "    else:\n",
        "        print(f\"\\n‚ùå TEST FAILED\")\n",
        "        print(f\"‚è±Ô∏è  Time: {result['elapsed_time']:.2f}s\")\n",
        "        print(f\"\\nüí• Error: {result.get('error')}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Compiling graph...\n",
            "‚úÖ Graph compiled successfully!\n"
          ]
        }
      ],
      "source": [
        "# Compile the graph\n",
        "print(\"Compiling graph...\")\n",
        "graph = compile_graph()\n",
        "print(\"‚úÖ Graph compiled successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test 1: Basic Flow - Address Input with Bachelor Profile\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "TEST: Test 1: Address + Bachelor Profile\n",
            "============================================================\n",
            "  ‚úì validate_input: validate_input: SUCCESS - Address detected, needs geocoding\n",
            "‚úÖ Loaded .env from: /Users/nitish.ranjan/Documents/AiDash/Educational/research/locality-lens/.env\n",
            "‚úÖ GROQ_API_KEY loaded (length: 56)\n",
            "  ‚úì extract_intent_and_select_metrics: extract_intent_and_select_metrics: SUCCESS - Extracted intent, selected 7 metrics\n",
            "  ‚úì geocode_location: geocode_location: SUCCESS - Geocoded to (12.9732913, 77.6404672)\n",
            "  ‚úì fetch_osm_data: fetch_osm_data: SUCCESS - Fetched 25 POI categories\n",
            "  ‚úì calculate_statistics: calculate_statistics: SUCCESS - Calculated 7 metrics\n",
            "  ‚úì generate_summary: generate_summary: SUCCESS - Summary generated\n",
            "\n",
            "‚úÖ TEST PASSED\n",
            "‚è±Ô∏è  Time: 14.69s\n",
            "\n",
            "‚ö†Ô∏è  Errors: 1\n",
            "   - Error calculating statistics: cannot access local variable 'area_km2' where it is not associated with a value\n",
            "\n",
            "‚ö†Ô∏è  Warnings: 1\n",
            "   - Road density calculation not yet implemented\n",
            "\n",
            "üìä Final State Summary:\n",
            "   - Coordinates: (12.9732913, 77.6404672)\n",
            "   - Address: Indiranagar, Jogpalya, Bengaluru Central City Corporation, Bengaluru, Bangalore East, Bengaluru Urban, Karnataka, 560008, India\n",
            "   - Selected Metrics: 5\n",
            "   - Statistics Count: 0\n",
            "   - Summary Generated: True\n",
            "   - User Intent: {'profile_type': 'bachelor', 'priorities': ['restaurants', 'nightlife', 'connectivity'], 'concerns': ['safety', 'noise'], 'lifestyle': 'Active, social, urban lifestyle', 'metric_selection_reasoning': 'Selected metrics based on user priorities for restaurants, nightlife, and connectivity'}\n",
            "\n",
            "üìù Generated Summary:\n",
            "------------------------------------------------------------\n",
            "Errors encountered:\n",
            "- Error calculating statistics: cannot access local variable 'area_km2' where it is not associated with a value\n",
            "\n",
            "Warnings:\n",
            "- Road density calculation not yet implemented\n"
          ]
        }
      ],
      "source": [
        "test1_state = create_initial_state(\n",
        "    user_input=\"Indiranagar, Bangalore\",\n",
        "    user_profile=\"Bachelor/Young Professional\"\n",
        ")\n",
        "\n",
        "result1 = run_test(graph, test1_state, \"Test 1: Address + Bachelor Profile\")\n",
        "print_test_results(result1, verbose=True)\n",
        "\n",
        "# Display summary if available\n",
        "if result1[\"success\"] and result1[\"final_state\"].get(\"summary\"):\n",
        "    print(f\"\\nüìù Generated Summary:\")\n",
        "    print(\"-\" * 60)\n",
        "    summary = result1[\"final_state\"][\"summary\"]\n",
        "    print(summary[:500] + \"...\" if len(summary) > 500 else summary)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test 2: Coordinates Input with Family Profile\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "TEST: Test 2: Coordinates + Family Profile\n",
            "============================================================\n",
            "  ‚úì validate_input: validate_input: SUCCESS - Address detected, needs geocoding\n",
            "  ‚úì extract_intent_and_select_metrics: extract_intent_and_select_metrics: SUCCESS - Extracted intent, selected 7 metrics\n",
            "  ‚úì geocode_location: geocode_location: SUCCESS - Geocoded to (28.4150509, 77.0642955)\n",
            "  ‚úì fetch_osm_data: fetch_osm_data: ERROR - cannot access local variable 'metro' where it is not associated with a value\n",
            "  ‚úì handle_error: handle_error: Error handling completed\n",
            "\n",
            "‚úÖ TEST PASSED\n",
            "‚è±Ô∏è  Time: 2.95s\n",
            "\n",
            "‚ö†Ô∏è  Errors: 1\n",
            "   - Error fetching OSM data: cannot access local variable 'metro' where it is not associated with a value\n",
            "\n",
            "üìä Final State Summary:\n",
            "   - Coordinates: None\n",
            "   - Address: None\n",
            "   - Selected Metrics: 0\n",
            "   - Statistics Count: 0\n",
            "   - Summary Generated: True\n",
            "   - User Intent: {}\n",
            "\n",
            "üìã Selected Metrics (0):\n"
          ]
        }
      ],
      "source": [
        "test2_state = create_initial_state(\n",
        "    user_input=\"Nirvana Country, Gurgaon\",  # Bangalore coordinates\n",
        "    user_profile=\"Family with Kids\"\n",
        ")\n",
        "\n",
        "result2 = run_test(graph, test2_state, \"Test 2: Coordinates + Family Profile\")\n",
        "print_test_results(result2, verbose=True)\n",
        "\n",
        "# Check selected metrics\n",
        "if result2[\"success\"]:\n",
        "    print(f\"\\nüìã Selected Metrics ({len(result2['final_state'].get('selected_metrics', []))}):\")\n",
        "    for metric in result2[\"final_state\"].get(\"selected_metrics\", [])[:10]:\n",
        "        print(f\"   - {metric}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test 3: Performance Benchmark - Multiple Locations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "TEST: Performance: Indiranagar, Bangalore\n",
            "============================================================\n",
            "  ‚úì validate_input: validate_input: SUCCESS - Address detected, needs geocoding\n",
            "  ‚úì extract_intent_and_select_metrics: extract_intent_and_select_metrics: SUCCESS - Extracted intent, selected 8 metrics\n",
            "  ‚úì geocode_location: geocode_location: SUCCESS - Geocoded to (12.9732913, 77.6404672)\n",
            "  ‚úì fetch_osm_data: fetch_osm_data: SUCCESS - Fetched 25 POI categories\n",
            "  ‚úì calculate_statistics: calculate_statistics: SUCCESS - Calculated 8 metrics\n",
            "  ‚úì generate_summary: generate_summary: SUCCESS - Summary generated\n",
            "\n",
            "‚úÖ TEST PASSED\n",
            "‚è±Ô∏è  Time: 27.39s\n",
            "\n",
            "‚ö†Ô∏è  Warnings: 2\n",
            "   - Road density calculation not yet implemented\n",
            "   - Road density calculation not yet implemented\n",
            "\n",
            "============================================================\n",
            "TEST: Performance: Nirvana Country, Gurgaon\n",
            "============================================================\n",
            "  ‚úì validate_input: validate_input: SUCCESS - Address detected, needs geocoding\n",
            "  ‚úì extract_intent_and_select_metrics: extract_intent_and_select_metrics: SUCCESS - Extracted intent, selected 8 metrics\n",
            "  ‚úì geocode_location: geocode_location: SUCCESS - Geocoded to (28.4150509, 77.0642955)\n",
            "  ‚úì fetch_osm_data: fetch_osm_data: ERROR - cannot access local variable 'metro' where it is not associated with a value\n",
            "  ‚úì handle_error: handle_error: Error handling completed\n",
            "\n",
            "‚úÖ TEST PASSED\n",
            "‚è±Ô∏è  Time: 11.68s\n",
            "\n",
            "‚ö†Ô∏è  Errors: 1\n",
            "   - Error fetching OSM data: cannot access local variable 'metro' where it is not associated with a value\n",
            "\n",
            "============================================================\n",
            "TEST: Performance: 12.9352, 77.6245\n",
            "============================================================\n",
            "  ‚úì validate_input: validate_input: SUCCESS - Parsed coordinates (12.9352, 77.6245)\n",
            "  ‚úì extract_intent_and_select_metrics: extract_intent_and_select_metrics: SUCCESS - Extracted intent, selected 7 metrics\n",
            "  ‚úì fetch_osm_data: fetch_osm_data: ERROR - cannot access local variable 'metro' where it is not associated with a value\n",
            "  ‚úì handle_error: handle_error: Error handling completed\n",
            "\n",
            "‚úÖ TEST PASSED\n",
            "‚è±Ô∏è  Time: 10.24s\n",
            "\n",
            "‚ö†Ô∏è  Errors: 1\n",
            "   - Error fetching OSM data: cannot access local variable 'metro' where it is not associated with a value\n",
            "\n",
            "============================================================\n",
            "üìä PERFORMANCE SUMMARY\n",
            "============================================================\n",
            "\n",
            "‚è±Ô∏è  Timing:\n",
            "   - Average: 16.43s\n",
            "   - Min: 10.24s\n",
            "   - Max: 27.39s\n",
            "\n",
            "üìã Details:\n",
            "   - Indiranagar, Bangalore         | 27.39s |  7 metrics |  7 stats\n",
            "   - Nirvana Country, Gurgaon       | 11.68s |  0 metrics |  0 stats\n",
            "   - 12.9352, 77.6245               | 10.24s |  0 metrics |  0 stats\n"
          ]
        }
      ],
      "source": [
        "test_locations = [\n",
        "    (\"Indiranagar, Bangalore\", \"Bachelor\"),\n",
        "    (\"Nirvana Country, Gurgaon\", \"Family\"),\n",
        "    (\"12.9352, 77.6245\", \"Student\"),  # Another Bangalore location\n",
        "]\n",
        "\n",
        "performance_results = []\n",
        "\n",
        "for location, profile in test_locations:\n",
        "    test_state = create_initial_state(\n",
        "        user_input=location,\n",
        "        user_profile=profile\n",
        "    )\n",
        "    \n",
        "    result = run_test(graph, test_state, f\"Performance: {location}\")\n",
        "    \n",
        "    if result[\"success\"]:\n",
        "        performance_results.append({\n",
        "            \"location\": location,\n",
        "            \"profile\": profile,\n",
        "            \"time\": result[\"elapsed_time\"],\n",
        "            \"metrics_count\": len(result[\"final_state\"].get(\"selected_metrics\", [])),\n",
        "            \"statistics_count\": len(result[\"final_state\"].get(\"statistics\", {})),\n",
        "            \"has_summary\": result[\"final_state\"].get(\"summary\") is not None\n",
        "        })\n",
        "    \n",
        "    print_test_results(result, verbose=False)\n",
        "\n",
        "# Summary\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"üìä PERFORMANCE SUMMARY\")\n",
        "print(f\"{'='*60}\")\n",
        "\n",
        "if performance_results:\n",
        "    avg_time = sum(r[\"time\"] for r in performance_results) / len(performance_results)\n",
        "    min_time = min(r[\"time\"] for r in performance_results)\n",
        "    max_time = max(r[\"time\"] for r in performance_results)\n",
        "    \n",
        "    print(f\"\\n‚è±Ô∏è  Timing:\")\n",
        "    print(f\"   - Average: {avg_time:.2f}s\")\n",
        "    print(f\"   - Min: {min_time:.2f}s\")\n",
        "    print(f\"   - Max: {max_time:.2f}s\")\n",
        "    \n",
        "    print(f\"\\nüìã Details:\")\n",
        "    for r in performance_results:\n",
        "        print(f\"   - {r['location']:30s} | {r['time']:5.2f}s | {r['metrics_count']:2d} metrics | {r['statistics_count']:2d} stats\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test 6: Extract GeoDataFrames for All Metrics & Data Cleaning Analysis\n",
        "\n",
        "This section extracts the actual GeoDataFrames (gdf) for all POI categories to:\n",
        "- Inspect raw data structure\n",
        "- Understand data quality issues\n",
        "- Demonstrate cleaning operations\n",
        "- Show before/after statistics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Fetching all POI GeoDataFrames...\n",
            "\n",
            "üìç Fetching OSM data for location: (28.4150509, 77.0642955)\n",
            "üìè Search radius: 2000m (2km)\n",
            "============================================================\n",
            "\n",
            "‚úÖ Fetched 2476 total features from OSM\n",
            "\n",
            "‚úÖ Extracted 17 POI categories\n",
            "\n",
            "üìä Categories found:\n",
            "   - banks               :   22 POIs\n",
            "   - cafes               :    3 POIs\n",
            "   - community           :    1 POIs\n",
            "   - fast_food           :    6 POIs\n",
            "   - gyms                :    2 POIs\n",
            "   - hospitals           :   29 POIs\n",
            "   - hotels              :    7 POIs\n",
            "   - kindergartens       :    2 POIs\n",
            "   - parks               :   89 POIs\n",
            "   - pharmacies          :    8 POIs\n",
            "   - playgrounds         :    2 POIs\n",
            "   - residential         :    1 POIs\n",
            "   - restaurants         :   29 POIs\n",
            "   - schools             :   26 POIs\n",
            "   - shops               :   62 POIs\n",
            "   - sports              :    2 POIs\n",
            "   - worship             :    2 POIs\n"
          ]
        }
      ],
      "source": [
        "import osmnx as ox\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import Point\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Configure OSMnx\n",
        "ox.settings.log_console = False\n",
        "ox.settings.use_cache = True\n",
        "ox.settings.timeout = 300\n",
        "\n",
        "def fetch_all_pois_gdf(location_point, radius=2000):\n",
        "    \"\"\"\n",
        "    Fetch all POI categories as GeoDataFrames.\n",
        "    \n",
        "    Returns a dictionary with category names as keys and GeoDataFrames as values.\n",
        "    \"\"\"\n",
        "    print(f\"üìç Fetching OSM data for location: {location_point}\")\n",
        "    print(f\"üìè Search radius: {radius}m (2km)\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "    \n",
        "    # Single optimized query for all POI categories\n",
        "    all_pois = ox.features_from_point(\n",
        "        location_point,\n",
        "        tags={\n",
        "            # Essential amenities\n",
        "            'amenity': [\n",
        "                'school', 'hospital', 'clinic', 'doctors', 'dentist',\n",
        "                'restaurant', 'cafe', 'fast_food', 'food_court',\n",
        "                'pharmacy', 'bank', 'atm', 'library', 'place_of_worship',\n",
        "                'community_centre', 'kindergarten', 'childcare', 'tuition',\n",
        "                'university', 'college', 'cinema', 'bar', 'pub', 'nightclub'\n",
        "            ],\n",
        "            # Leisure & recreation\n",
        "            'leisure': [\n",
        "                'park', 'garden', 'recreation_ground', 'playground',\n",
        "                'fitness_centre', 'gym', 'sports_centre'\n",
        "            ],\n",
        "            # Transportation\n",
        "            'railway': 'station',\n",
        "            'highway': 'bus_stop',\n",
        "            # Shopping\n",
        "            'shop': True,  # All shop types\n",
        "            # Tourism\n",
        "            'tourism': ['hotel', 'attraction'],\n",
        "            # Buildings (for residential density)\n",
        "            'building': 'residential',\n",
        "            # Roads (for road density)\n",
        "            'highway': ['primary', 'secondary', 'tertiary', 'residential', 'cycleway']\n",
        "        },\n",
        "        dist=radius\n",
        "    )\n",
        "    \n",
        "    print(f\"‚úÖ Fetched {len(all_pois)} total features from OSM\\n\")\n",
        "    \n",
        "    # Classify into categories\n",
        "    gdfs = {}\n",
        "    \n",
        "    if not all_pois.empty:\n",
        "        # Schools\n",
        "        if 'amenity' in all_pois.columns:\n",
        "            gdfs['schools'] = all_pois[all_pois['amenity'] == 'school'].copy()\n",
        "            \n",
        "            # Hospitals & Clinics\n",
        "            gdfs['hospitals'] = all_pois[all_pois['amenity'].isin(['hospital', 'clinic', 'doctors', 'dentist'])].copy()\n",
        "            \n",
        "            # Restaurants (combined)\n",
        "            gdfs['restaurants'] = all_pois[all_pois['amenity'].isin(['restaurant', 'cafe', 'fast_food', 'food_court'])].copy()\n",
        "            \n",
        "            # Cafes (separate)\n",
        "            gdfs['cafes'] = all_pois[all_pois['amenity'] == 'cafe'].copy()\n",
        "            \n",
        "            # Fast food (separate)\n",
        "            gdfs['fast_food'] = all_pois[all_pois['amenity'] == 'fast_food'].copy()\n",
        "            \n",
        "            # Banks & ATMs\n",
        "            gdfs['banks'] = all_pois[all_pois['amenity'].isin(['bank', 'atm'])].copy()\n",
        "            \n",
        "            # Pharmacies\n",
        "            gdfs['pharmacies'] = all_pois[all_pois['amenity'] == 'pharmacy'].copy()\n",
        "            \n",
        "            # Gyms & Fitness\n",
        "            gdfs['gyms'] = all_pois[all_pois['amenity'].isin(['gym', 'fitness_centre'])].copy()\n",
        "            if 'leisure' in all_pois.columns:\n",
        "                gyms_leisure = all_pois[all_pois['leisure'].isin(['fitness_centre', 'gym'])].copy()\n",
        "                gdfs['gyms'] = pd.concat([gdfs['gyms'], gyms_leisure]).drop_duplicates()\n",
        "            \n",
        "            # Libraries\n",
        "            gdfs['libraries'] = all_pois[all_pois['amenity'] == 'library'].copy()\n",
        "            \n",
        "            # Places of Worship\n",
        "            gdfs['worship'] = all_pois[all_pois['amenity'] == 'place_of_worship'].copy()\n",
        "            \n",
        "            # Nightlife\n",
        "            gdfs['nightlife'] = all_pois[all_pois['amenity'].isin(['bar', 'pub', 'nightclub'])].copy()\n",
        "            \n",
        "            # Cinemas\n",
        "            gdfs['cinemas'] = all_pois[all_pois['amenity'] == 'cinema'].copy()\n",
        "            \n",
        "            # Universities\n",
        "            gdfs['universities'] = all_pois[all_pois['amenity'].isin(['university', 'college'])].copy()\n",
        "            \n",
        "            # Kindergartens\n",
        "            gdfs['kindergartens'] = all_pois[all_pois['amenity'] == 'kindergarten'].copy()\n",
        "            \n",
        "            # Childcare\n",
        "            gdfs['childcare'] = all_pois[all_pois['amenity'] == 'childcare'].copy()\n",
        "            \n",
        "            # Tuition\n",
        "            gdfs['tuition'] = all_pois[all_pois['amenity'] == 'tuition'].copy()\n",
        "            \n",
        "            # Community Centres\n",
        "            gdfs['community'] = all_pois[all_pois['amenity'] == 'community_centre'].copy()\n",
        "        \n",
        "        # Parks & Gardens\n",
        "        if 'leisure' in all_pois.columns:\n",
        "            gdfs['parks'] = all_pois[all_pois['leisure'].isin(['park', 'garden', 'recreation_ground'])].copy()\n",
        "            \n",
        "            # Playgrounds\n",
        "            gdfs['playgrounds'] = all_pois[all_pois['leisure'] == 'playground'].copy()\n",
        "            \n",
        "            # Sports facilities\n",
        "            gdfs['sports'] = all_pois[all_pois['leisure'] == 'sports_centre'].copy()\n",
        "        \n",
        "        # Transportation\n",
        "        if 'railway' in all_pois.columns:\n",
        "            gdfs['metro_stations'] = all_pois[all_pois['railway'] == 'station'].copy()\n",
        "        \n",
        "        if 'highway' in all_pois.columns:\n",
        "            gdfs['bus_stops'] = all_pois[all_pois['highway'] == 'bus_stop'].copy()\n",
        "        \n",
        "        # Shopping\n",
        "        if 'shop' in all_pois.columns:\n",
        "            gdfs['shops'] = all_pois[all_pois['shop'].notna()].copy()\n",
        "        \n",
        "        # Hotels\n",
        "        if 'tourism' in all_pois.columns:\n",
        "            gdfs['hotels'] = all_pois[all_pois['tourism'] == 'hotel'].copy()\n",
        "        \n",
        "        # Residential buildings\n",
        "        if 'building' in all_pois.columns:\n",
        "            gdfs['residential'] = all_pois[all_pois['building'] == 'residential'].copy()\n",
        "    \n",
        "    # Remove empty categories\n",
        "    gdfs = {k: v for k, v in gdfs.items() if not v.empty}\n",
        "    \n",
        "    return gdfs\n",
        "\n",
        "\n",
        "def analyze_gdf_quality(gdf, category_name):\n",
        "    \"\"\"\n",
        "    Analyze data quality of a GeoDataFrame.\n",
        "    \n",
        "    Returns a dictionary with quality metrics.\n",
        "    \"\"\"\n",
        "    if gdf.empty:\n",
        "        return {\n",
        "            'total_count': 0,\n",
        "            'has_geometry': 0,\n",
        "            'valid_geometry': 0,\n",
        "            'has_name': 0,\n",
        "            'duplicate_names': 0,\n",
        "            'null_geometries': 0,\n",
        "            'invalid_geometries': 0,\n",
        "            'empty_geometries': 0\n",
        "        }\n",
        "    \n",
        "    analysis = {\n",
        "        'total_count': len(gdf),\n",
        "        'has_geometry': gdf['geometry'].notna().sum() if 'geometry' in gdf.columns else 0,\n",
        "        'valid_geometry': 0,\n",
        "        'has_name': gdf['name'].notna().sum() if 'name' in gdf.columns else 0,\n",
        "        'duplicate_names': 0,\n",
        "        'null_geometries': gdf['geometry'].isna().sum() if 'geometry' in gdf.columns else 0,\n",
        "        'invalid_geometries': 0,\n",
        "        'empty_geometries': 0\n",
        "    }\n",
        "    \n",
        "    if 'geometry' in gdf.columns:\n",
        "        analysis['valid_geometry'] = gdf['geometry'].apply(lambda g: g.is_valid if g is not None else False).sum()\n",
        "        analysis['empty_geometries'] = gdf['geometry'].apply(lambda g: g.is_empty if g is not None else True).sum()\n",
        "        analysis['invalid_geometries'] = analysis['total_count'] - analysis['valid_geometry'] - analysis['null_geometries']\n",
        "    \n",
        "    if 'name' in gdf.columns:\n",
        "        name_counts = gdf['name'].value_counts()\n",
        "        analysis['duplicate_names'] = (name_counts > 1).sum()\n",
        "    \n",
        "    return analysis\n",
        "\n",
        "\n",
        "def clean_gdf(gdf, category_name=\"\"):\n",
        "    \"\"\"\n",
        "    Clean a GeoDataFrame using the same logic as the production code.\n",
        "    \n",
        "    This is a copy of the clean_and_deduplicate_pois function for testing.\n",
        "    \"\"\"\n",
        "    if gdf.empty:\n",
        "        return gdf\n",
        "    \n",
        "    original_count = len(gdf)\n",
        "    \n",
        "    # Remove entries without valid geometry\n",
        "    if 'geometry' in gdf.columns:\n",
        "        gdf = gdf[gdf['geometry'].notna()].copy()\n",
        "        gdf = gdf[~gdf['geometry'].is_empty].copy()\n",
        "        gdf = gdf[gdf['geometry'].is_valid].copy()\n",
        "    \n",
        "    # Deduplicate by normalized name (case-insensitive)\n",
        "    if 'name' in gdf.columns:\n",
        "        gdf['_name_normalized'] = (\n",
        "            gdf['name']\n",
        "            .fillna('')\n",
        "            .astype(str)\n",
        "            .str.lower()\n",
        "            .str.strip()\n",
        "            .str.replace(r'\\s+', ' ', regex=True)\n",
        "        )\n",
        "        gdf = gdf.drop_duplicates(subset=['_name_normalized'], keep='first')\n",
        "        gdf = gdf.drop(columns=['_name_normalized'], errors='ignore')\n",
        "    \n",
        "    # Deduplicate by location (if same name at same location)\n",
        "    if 'name' in gdf.columns and 'geometry' in gdf.columns and not gdf.empty:\n",
        "        try:\n",
        "            gdf['_name_norm'] = gdf['name'].fillna('').astype(str).str.lower().str.strip()\n",
        "            gdf = gdf.drop_duplicates(subset=['_name_norm', 'geometry'], keep='first')\n",
        "            gdf = gdf.drop(columns=['_name_norm'], errors='ignore')\n",
        "        except Exception:\n",
        "            pass\n",
        "    \n",
        "    cleaned_count = len(gdf)\n",
        "    removed = original_count - cleaned_count\n",
        "    \n",
        "    return gdf\n",
        "\n",
        "\n",
        "# Test location\n",
        "test_location = (28.4150509, 77.0642955)  # Indiranagar, Bangalore\n",
        "\n",
        "print(\"üîç Fetching all POI GeoDataFrames...\\n\")\n",
        "all_gdfs = fetch_all_pois_gdf(test_location, radius=2000)\n",
        "\n",
        "print(f\"‚úÖ Extracted {len(all_gdfs)} POI categories\\n\")\n",
        "print(\"üìä Categories found:\")\n",
        "for category in sorted(all_gdfs.keys()):\n",
        "    count = len(all_gdfs[category])\n",
        "    print(f\"   - {category:20s}: {count:4d} POIs\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Quality Analysis: Before Cleaning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "üìä DATA QUALITY ANALYSIS - BEFORE CLEANING\n",
            "================================================================================\n",
            "\n",
            "üìã Summary Statistics:\n",
            "                total_count  has_geometry  valid_geometry  has_name  duplicate_names  null_geometries  invalid_geometries  empty_geometries\n",
            "shops                  1043          1043            1043       985               37                0                   0                 0\n",
            "restaurants             529           529             529       527               21                0                   0                 0\n",
            "residential             397           397             397        38                0                0                   0                 0\n",
            "hospitals               181           181             181       177                3                0                   0                 0\n",
            "banks                   176           176             176       147               23                0                   0                 0\n",
            "worship                 156           156             156       117                5                0                   0                 0\n",
            "fast_food               125           125             125       125                7                0                   0                 0\n",
            "cafes                   101           101             101       101                5                0                   0                 0\n",
            "parks                    89            89              89        36                2                0                   0                 0\n",
            "pharmacies               85            85              85        71                3                0                   0                 0\n",
            "schools                  76            76              76        72                2                0                   0                 0\n",
            "nightlife                45            45              45        44                0                0                   0                 0\n",
            "playgrounds              33            33              33         6                1                0                   0                 0\n",
            "hotels                   25            25              25        24                1                0                   0                 0\n",
            "sports                   22            22              22        21                0                0                   0                 0\n",
            "gyms                     18            18              18        17                2                0                   0                 0\n",
            "universities             17            17              17        17                1                0                   0                 0\n",
            "community                14            14              14        13                0                0                   0                 0\n",
            "kindergartens            12            12              12        12                0                0                   0                 0\n",
            "libraries                 7             7               7         7                0                0                   0                 0\n",
            "metro_stations            5             5               5         5                0                0                   0                 0\n",
            "childcare                 2             2               2         2                0                0                   0                 0\n",
            "\n",
            "\n",
            "üîç Key Quality Issues:\n",
            "   - Categories with null geometries: 0\n",
            "   - Categories with invalid geometries: 0\n",
            "   - Categories with duplicate names: 14\n",
            "   - Total POIs across all categories: 3158\n",
            "   - POIs without names: 594\n",
            "\n",
            "\n",
            "‚ö†Ô∏è  Examples of Data Quality Issues:\n",
            "\n",
            "üìå Top 5 categories with duplicate names:\n",
            "   - shops               : 37 duplicates out of 1043 total\n",
            "   - banks               : 23 duplicates out of 176 total\n",
            "   - restaurants         : 21 duplicates out of 529 total\n",
            "   - fast_food           : 7 duplicates out of 125 total\n",
            "   - worship             : 5 duplicates out of 156 total\n",
            "\n",
            "\n",
            "üìù Sample Raw Data (First 3 rows from 'restaurants'):\n",
            "                             name     amenity                   geometry\n",
            "element id                                                              \n",
            "node    312503506    Shanti Sagar  restaurant   POINT (77.6385 12.96066)\n",
            "        312504927  Srinidhi Sagar   fast_food  POINT (77.63859 12.95934)\n",
            "        312508904        Nandhini  restaurant  POINT (77.64191 12.96195)\n"
          ]
        }
      ],
      "source": [
        "# Analyze data quality for all categories BEFORE cleaning\n",
        "print(\"=\"*80)\n",
        "print(\"üìä DATA QUALITY ANALYSIS - BEFORE CLEANING\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "quality_before = {}\n",
        "\n",
        "for category, gdf in all_gdfs.items():\n",
        "    quality_before[category] = analyze_gdf_quality(gdf, category)\n",
        "\n",
        "# Create summary DataFrame\n",
        "quality_df = pd.DataFrame(quality_before).T\n",
        "quality_df = quality_df.sort_values('total_count', ascending=False)\n",
        "\n",
        "print(\"\\nüìã Summary Statistics:\")\n",
        "print(quality_df.to_string())\n",
        "\n",
        "print(\"\\n\\nüîç Key Quality Issues:\")\n",
        "print(f\"   - Categories with null geometries: {(quality_df['null_geometries'] > 0).sum()}\")\n",
        "print(f\"   - Categories with invalid geometries: {(quality_df['invalid_geometries'] > 0).sum()}\")\n",
        "print(f\"   - Categories with duplicate names: {(quality_df['duplicate_names'] > 0).sum()}\")\n",
        "print(f\"   - Total POIs across all categories: {quality_df['total_count'].sum()}\")\n",
        "print(f\"   - POIs without names: {quality_df['total_count'].sum() - quality_df['has_name'].sum()}\")\n",
        "\n",
        "# Show examples of problematic data\n",
        "print(\"\\n\\n‚ö†Ô∏è  Examples of Data Quality Issues:\\n\")\n",
        "\n",
        "# Show categories with most duplicates\n",
        "if quality_df['duplicate_names'].sum() > 0:\n",
        "    print(\"üìå Top 5 categories with duplicate names:\")\n",
        "    top_duplicates = quality_df.nlargest(5, 'duplicate_names')[['total_count', 'duplicate_names']]\n",
        "    for category, row in top_duplicates.iterrows():\n",
        "        if row['duplicate_names'] > 0:\n",
        "            print(f\"   - {category:20s}: {int(row['duplicate_names'])} duplicates out of {int(row['total_count'])} total\")\n",
        "\n",
        "# Show sample of data with issues\n",
        "print(\"\\n\\nüìù Sample Raw Data (First 3 rows from 'restaurants'):\")\n",
        "if 'restaurants' in all_gdfs and not all_gdfs['restaurants'].empty:\n",
        "    sample = all_gdfs['restaurants'].head(3)\n",
        "    print(sample[['name', 'amenity', 'geometry']].to_string() if 'name' in sample.columns else sample.head(3).to_string())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Apply Cleaning & Compare Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "üßπ APPLYING DATA CLEANING\n",
            "================================================================================\n",
            "‚úÖ schools             :   76 ‚Üí   71 (removed   5, 6.6%)\n",
            "‚úÖ hospitals           :  181 ‚Üí  173 (removed   8, 4.4%)\n",
            "‚úÖ restaurants         :  529 ‚Üí  496 (removed  33, 6.2%)\n",
            "‚úÖ cafes               :  101 ‚Üí   91 (removed  10, 9.9%)\n",
            "‚úÖ fast_food           :  125 ‚Üí  114 (removed  11, 8.8%)\n",
            "‚úÖ banks               :  176 ‚Üí   55 (removed 121, 68.8%)\n",
            "‚úÖ pharmacies          :   85 ‚Üí   62 (removed  23, 27.1%)\n",
            "‚úÖ gyms                :   18 ‚Üí   16 (removed   2, 11.1%)\n",
            "‚úÖ libraries           :    7 ‚Üí    7 (no changes)\n",
            "‚úÖ worship             :  156 ‚Üí  101 (removed  55, 35.3%)\n",
            "‚úÖ nightlife           :   45 ‚Üí   45 (no changes)\n",
            "‚úÖ universities        :   17 ‚Üí   16 (removed   1, 5.9%)\n",
            "‚úÖ kindergartens       :   12 ‚Üí   12 (no changes)\n",
            "‚úÖ childcare           :    2 ‚Üí    2 (no changes)\n",
            "‚úÖ community           :   14 ‚Üí   14 (no changes)\n",
            "‚úÖ parks               :   89 ‚Üí   35 (removed  54, 60.7%)\n",
            "‚úÖ playgrounds         :   33 ‚Üí    6 (removed  27, 81.8%)\n",
            "‚úÖ sports              :   22 ‚Üí   22 (no changes)\n",
            "‚úÖ metro_stations      :    5 ‚Üí    5 (no changes)\n",
            "‚úÖ shops               : 1043 ‚Üí  923 (removed 120, 11.5%)\n",
            "‚úÖ hotels              :   25 ‚Üí   24 (removed   1, 4.0%)\n",
            "‚úÖ residential         :  397 ‚Üí   39 (removed 358, 90.2%)\n",
            "\n",
            "üìä Cleaning Summary:\n",
            "   - Total POIs before: 3158\n",
            "   - Total POIs after:  2329\n",
            "   - Total removed:     829 (26.3%)\n",
            "\n",
            "================================================================================\n",
            "üìä DATA QUALITY ANALYSIS - AFTER CLEANING\n",
            "================================================================================\n",
            "\n",
            "üìã Summary Statistics (After Cleaning):\n",
            "                total_count  has_geometry  valid_geometry  has_name  duplicate_names  null_geometries  invalid_geometries  empty_geometries\n",
            "shops                   923           923             923       922                0                0                   0                 0\n",
            "restaurants             496           496             496       495                0                0                   0                 0\n",
            "hospitals               173           173             173       172                0                0                   0                 0\n",
            "fast_food               114           114             114       114                0                0                   0                 0\n",
            "worship                 101           101             101       100                0                0                   0                 0\n",
            "cafes                    91            91              91        91                0                0                   0                 0\n",
            "schools                  71            71              71        70                0                0                   0                 0\n",
            "pharmacies               62            62              62        61                0                0                   0                 0\n",
            "banks                    55            55              55        54                0                0                   0                 0\n",
            "nightlife                45            45              45        44                0                0                   0                 0\n",
            "residential              39            39              39        38                0                0                   0                 0\n",
            "parks                    35            35              35        34                0                0                   0                 0\n",
            "hotels                   24            24              24        23                0                0                   0                 0\n",
            "sports                   22            22              22        21                0                0                   0                 0\n",
            "gyms                     16            16              16        15                0                0                   0                 0\n",
            "universities             16            16              16        16                0                0                   0                 0\n",
            "community                14            14              14        13                0                0                   0                 0\n",
            "kindergartens            12            12              12        12                0                0                   0                 0\n",
            "libraries                 7             7               7         7                0                0                   0                 0\n",
            "playgrounds               6             6               6         5                0                0                   0                 0\n",
            "metro_stations            5             5               5         5                0                0                   0                 0\n",
            "childcare                 2             2               2         2                0                0                   0                 0\n",
            "\n",
            "\n",
            "================================================================================\n",
            "üìà BEFORE vs AFTER COMPARISON\n",
            "================================================================================\n",
            "\n",
            "üìä Cleaning Impact by Category:\n",
            "          category  count_before  count_after  removed  duplicates_before  duplicates_after  invalid_geom_before  invalid_geom_after\n",
            "21     residential           397           39      358                  0                 0                    0                   0\n",
            "5            banks           176           55      121                 23                 0                    0                   0\n",
            "19           shops          1043          923      120                 37                 0                    0                   0\n",
            "9          worship           156          101       55                  5                 0                    0                   0\n",
            "15           parks            89           35       54                  2                 0                    0                   0\n",
            "2      restaurants           529          496       33                 21                 0                    0                   0\n",
            "16     playgrounds            33            6       27                  1                 0                    0                   0\n",
            "6       pharmacies            85           62       23                  3                 0                    0                   0\n",
            "4        fast_food           125          114       11                  7                 0                    0                   0\n",
            "3            cafes           101           91       10                  5                 0                    0                   0\n",
            "1        hospitals           181          173        8                  3                 0                    0                   0\n",
            "0          schools            76           71        5                  2                 0                    0                   0\n",
            "7             gyms            18           16        2                  2                 0                    0                   0\n",
            "20          hotels            25           24        1                  1                 0                    0                   0\n",
            "11    universities            17           16        1                  1                 0                    0                   0\n",
            "12   kindergartens            12           12        0                  0                 0                    0                   0\n",
            "13       childcare             2            2        0                  0                 0                    0                   0\n",
            "14       community            14           14        0                  0                 0                    0                   0\n",
            "10       nightlife            45           45        0                  0                 0                    0                   0\n",
            "8        libraries             7            7        0                  0                 0                    0                   0\n",
            "17          sports            22           22        0                  0                 0                    0                   0\n",
            "18  metro_stations             5            5        0                  0                 0                    0                   0\n"
          ]
        }
      ],
      "source": [
        "# Clean all GeoDataFrames\n",
        "print(\"=\"*80)\n",
        "print(\"üßπ APPLYING DATA CLEANING\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "cleaned_gdfs = {}\n",
        "cleaning_stats = {}\n",
        "\n",
        "for category, gdf in all_gdfs.items():\n",
        "    original_count = len(gdf)\n",
        "    cleaned = clean_gdf(gdf.copy(), category)\n",
        "    cleaned_count = len(cleaned)\n",
        "    removed = original_count - cleaned_count\n",
        "    removal_pct = (removed / original_count * 100) if original_count > 0 else 0\n",
        "    \n",
        "    cleaned_gdfs[category] = cleaned\n",
        "    cleaning_stats[category] = {\n",
        "        'before': original_count,\n",
        "        'after': cleaned_count,\n",
        "        'removed': removed,\n",
        "        'removal_pct': removal_pct\n",
        "    }\n",
        "    \n",
        "    if removed > 0:\n",
        "        print(f\"‚úÖ {category:20s}: {original_count:4d} ‚Üí {cleaned_count:4d} (removed {removed:3d}, {removal_pct:.1f}%)\")\n",
        "    else:\n",
        "        print(f\"‚úÖ {category:20s}: {original_count:4d} ‚Üí {cleaned_count:4d} (no changes)\")\n",
        "\n",
        "print(f\"\\nüìä Cleaning Summary:\")\n",
        "total_before = sum(s['before'] for s in cleaning_stats.values())\n",
        "total_after = sum(s['after'] for s in cleaning_stats.values())\n",
        "total_removed = total_before - total_after\n",
        "\n",
        "print(f\"   - Total POIs before: {total_before}\")\n",
        "print(f\"   - Total POIs after:  {total_after}\")\n",
        "print(f\"   - Total removed:     {total_removed} ({total_removed/total_before*100:.1f}%)\")\n",
        "\n",
        "# Analyze quality AFTER cleaning\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üìä DATA QUALITY ANALYSIS - AFTER CLEANING\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "quality_after = {}\n",
        "\n",
        "for category, gdf in cleaned_gdfs.items():\n",
        "    quality_after[category] = analyze_gdf_quality(gdf, category)\n",
        "\n",
        "quality_after_df = pd.DataFrame(quality_after).T\n",
        "quality_after_df = quality_after_df.sort_values('total_count', ascending=False)\n",
        "\n",
        "print(\"\\nüìã Summary Statistics (After Cleaning):\")\n",
        "print(quality_after_df.to_string())\n",
        "\n",
        "# Compare before and after\n",
        "print(\"\\n\\n\" + \"=\"*80)\n",
        "print(\"üìà BEFORE vs AFTER COMPARISON\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "comparison_data = []\n",
        "for category in quality_before.keys():\n",
        "    before = quality_before[category]\n",
        "    after = quality_after.get(category, {})\n",
        "    comparison_data.append({\n",
        "        'category': category,\n",
        "        'count_before': before['total_count'],\n",
        "        'count_after': after.get('total_count', 0),\n",
        "        'removed': before['total_count'] - after.get('total_count', 0),\n",
        "        'duplicates_before': before['duplicate_names'],\n",
        "        'duplicates_after': after.get('duplicate_names', 0),\n",
        "        'invalid_geom_before': before['invalid_geometries'],\n",
        "        'invalid_geom_after': after.get('invalid_geometries', 0)\n",
        "    })\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_data)\n",
        "comparison_df = comparison_df.sort_values('removed', ascending=False)\n",
        "\n",
        "print(\"\\nüìä Cleaning Impact by Category:\")\n",
        "print(comparison_df.to_string())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Inspect Individual GeoDataFrames\n",
        "\n",
        "Select a category to inspect its cleaned GeoDataFrame:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select a category to inspect (change this to explore different categories)\n",
        "category_to_inspect = 'restaurants'  # Try: 'schools', 'hospitals', 'parks', 'shops', etc.\n",
        "\n",
        "if category_to_inspect in cleaned_gdfs:\n",
        "    gdf = cleaned_gdfs[category_to_inspect]\n",
        "    \n",
        "    print(\"=\"*80)\n",
        "    print(f\"üîç INSPECTING: {category_to_inspect.upper()}\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    print(f\"\\nüìä Basic Info:\")\n",
        "    print(f\"   - Total POIs: {len(gdf)}\")\n",
        "    print(f\"   - Columns: {len(gdf.columns)}\")\n",
        "    print(f\"   - CRS: {gdf.crs if hasattr(gdf, 'crs') else 'Not set'}\")\n",
        "    \n",
        "    print(f\"\\nüìã Column Names:\")\n",
        "    print(f\"   {', '.join(gdf.columns[:10].tolist())}\")\n",
        "    if len(gdf.columns) > 10:\n",
        "        print(f\"   ... and {len(gdf.columns) - 10} more columns\")\n",
        "    \n",
        "    print(f\"\\nüìù Sample Data (First 5 rows):\")\n",
        "    # Show key columns if available\n",
        "    key_cols = ['name', 'amenity', 'leisure', 'geometry']\n",
        "    available_cols = [col for col in key_cols if col in gdf.columns]\n",
        "    \n",
        "    if available_cols:\n",
        "        display_df = gdf[available_cols].head(5).copy()\n",
        "        # Format geometry for display\n",
        "        if 'geometry' in display_df.columns:\n",
        "            display_df['geometry'] = display_df['geometry'].apply(\n",
        "                lambda g: f\"Point({g.x:.6f}, {g.y:.6f})\" if hasattr(g, 'x') else str(g)[:50]\n",
        "            )\n",
        "        print(display_df.to_string())\n",
        "    else:\n",
        "        print(gdf.head(5).to_string())\n",
        "    \n",
        "    print(f\"\\nüìà Data Quality:\")\n",
        "    quality = analyze_gdf_quality(gdf, category_to_inspect)\n",
        "    for key, value in quality.items():\n",
        "        print(f\"   - {key:20s}: {value}\")\n",
        "    \n",
        "    # Show names if available\n",
        "    if 'name' in gdf.columns:\n",
        "        print(f\"\\nüìõ POI Names (sample):\")\n",
        "        names = gdf['name'].dropna().head(10).tolist()\n",
        "        for i, name in enumerate(names, 1):\n",
        "            print(f\"   {i:2d}. {name}\")\n",
        "        if len(gdf['name'].dropna()) > 10:\n",
        "            print(f\"   ... and {len(gdf['name'].dropna()) - 10} more\")\n",
        "    \n",
        "    # Show statistics\n",
        "    print(f\"\\nüìä Statistics:\")\n",
        "    if 'name' in gdf.columns:\n",
        "        print(f\"   - POIs with names: {gdf['name'].notna().sum()} ({gdf['name'].notna().sum()/len(gdf)*100:.1f}%)\")\n",
        "        print(f\"   - Unique names: {gdf['name'].nunique()}\")\n",
        "    \n",
        "    if 'geometry' in gdf.columns:\n",
        "        print(f\"   - Valid geometries: {gdf['geometry'].apply(lambda g: g.is_valid if g is not None else False).sum()}\")\n",
        "        \n",
        "else:\n",
        "    print(f\"‚ùå Category '{category_to_inspect}' not found.\")\n",
        "    print(f\"Available categories: {', '.join(sorted(cleaned_gdfs.keys()))}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Export All Cleaned GeoDataFrames\n",
        "\n",
        "Export cleaned GeoDataFrames for further analysis:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export all cleaned GeoDataFrames\n",
        "# You can access them via: cleaned_gdfs['category_name']\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"üíæ EXPORTED CLEANED GEODATAFRAMES\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\n‚úÖ All cleaned GeoDataFrames are stored in the 'cleaned_gdfs' dictionary\")\n",
        "print(\"\\nüìã Available categories:\")\n",
        "for i, category in enumerate(sorted(cleaned_gdfs.keys()), 1):\n",
        "    count = len(cleaned_gdfs[category])\n",
        "    print(f\"   {i:2d}. {category:20s}: {count:4d} POIs\")\n",
        "\n",
        "print(\"\\nüí° Usage Examples:\")\n",
        "print(\"   # Access a specific category:\")\n",
        "print(\"   restaurants_gdf = cleaned_gdfs['restaurants']\")\n",
        "print(\"   schools_gdf = cleaned_gdfs['schools']\")\n",
        "print(\"\")\n",
        "print(\"   # Get all POI names:\")\n",
        "print(\"   restaurant_names = cleaned_gdfs['restaurants']['name'].dropna().tolist()\")\n",
        "print(\"\")\n",
        "print(\"   # Get coordinates:\")\n",
        "print(\"   restaurant_coords = cleaned_gdfs['restaurants']['geometry'].apply(lambda g: (g.x, g.y) if hasattr(g, 'x') else None)\")\n",
        "print(\"\")\n",
        "print(\"   # Filter by name:\")\n",
        "print(\"   specific_restaurant = cleaned_gdfs['restaurants'][cleaned_gdfs['restaurants']['name'] == 'Restaurant Name']\")\n",
        "print(\"\")\n",
        "print(\"   # Export to file:\")\n",
        "print(\"   cleaned_gdfs['restaurants'].to_file('restaurants.geojson', driver='GeoJSON')\")\n",
        "\n",
        "# Create a summary DataFrame\n",
        "summary_data = []\n",
        "for category, gdf in cleaned_gdfs.items():\n",
        "    summary_data.append({\n",
        "        'category': category,\n",
        "        'count': len(gdf),\n",
        "        'has_names': gdf['name'].notna().sum() if 'name' in gdf.columns else 0,\n",
        "        'unique_names': gdf['name'].nunique() if 'name' in gdf.columns else 0,\n",
        "        'valid_geometries': gdf['geometry'].apply(lambda g: g.is_valid if g is not None else False).sum() if 'geometry' in gdf.columns else 0\n",
        "    })\n",
        "\n",
        "summary_df = pd.DataFrame(summary_data)\n",
        "summary_df = summary_df.sort_values('count', ascending=False)\n",
        "\n",
        "print(\"\\n\\nüìä Final Summary:\")\n",
        "print(summary_df.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test 4: State Inspection - Full Workflow Trace\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "TEST: Test 4: Full State Inspection\n",
            "============================================================\n",
            "  ‚úì validate_input: validate_input: SUCCESS - Address detected, needs geocoding\n",
            "  ‚úì extract_intent_and_select_metrics: extract_intent_and_select_metrics: SUCCESS - Extracted intent, selected 7 metrics\n",
            "  ‚úì geocode_location: geocode_location: SUCCESS - Geocoded to (12.9116225, 77.6388622)\n",
            "  ‚úì fetch_osm_data: fetch_osm_data: SUCCESS - Fetched 25 POI categories\n",
            "  ‚úì calculate_statistics: calculate_statistics: SUCCESS - Calculated 7 metrics\n",
            "  ‚úì generate_summary: generate_summary: SUCCESS - Summary generated\n",
            "\n",
            "============================================================\n",
            "üîç COMPLETE STATE INSPECTION\n",
            "============================================================\n",
            "\n",
            "üì• Input:\n",
            "   - User Input: HSR Layout, Bangalore\n",
            "   - User Profile: Senior Citizen\n",
            "\n",
            "üåç Geocoding:\n",
            "   - Coordinates: (12.9116225, 77.6388622)\n",
            "   - Address: HSR Layout, Bengaluru South City Corporation, Bengaluru, Bangalore South, Bengaluru Urban, Karnataka, India\n",
            "\n",
            "üéØ User Intent:\n",
            "{'concerns': ['accessibility', 'comfort'],\n",
            " 'lifestyle': 'Comfortable, relaxed, community-based lifestyle',\n",
            " 'metric_selection_reasoning': 'Selected metrics based on user priorities for '\n",
            "                               'healthcare, amenities, and safety, considering '\n",
            "                               'their senior citizen profile',\n",
            " 'priorities': ['healthcare', 'amenities', 'safety'],\n",
            " 'profile_type': 'senior_citizen'}\n",
            "\n",
            "üìä Selected Metrics (7):\n",
            "   - hospital_count\n",
            "   - pharmacy_count\n",
            "   - gym_fitness_count\n",
            "   - park_area_km2\n",
            "   - library_count\n",
            "   - bus_stop_count\n",
            "   - walkability_score\n",
            "\n",
            "üìà Statistics (7):\n",
            "   - hospital_count: 0\n",
            "   - pharmacy_count: 0\n",
            "   - gym_fitness_count: 13\n",
            "   - park_area_km2: 3.0\n",
            "   - library_count: 0\n",
            "   - bus_stop_count: 0\n",
            "   - walkability_score: 0.0\n",
            "\n",
            "üìù Summary:\n",
            "**Summary of HSR Layout, Bengaluru South City Corporation**\n",
            "\n",
            "HSR Layout, located in Bengaluru, is a vibrant and bustling locality that offers a unique blend of convenience, recreation, and connectivity. The area boasts an impressive array of amenities, including 493 shops, 11 hotels, and 10 resident...\n",
            "\n",
            "üìã Processing Steps (12):\n",
            "   - validate_input: SUCCESS - Address detected, needs geocoding\n",
            "   - extract_intent_and_select_metrics: SUCCESS - Extracted intent, selected 7 metrics\n",
            "   - geocode_location: SUCCESS - Geocoded to (12.9116225, 77.6388622)\n",
            "   - fetch_osm_data: SUCCESS - Fetched 25 POI categories\n",
            "   - calculate_statistics: SUCCESS - Calculated 7 metrics\n",
            "   - generate_summary: SUCCESS - Summary generated\n",
            "   - validate_input: SUCCESS - Address detected, needs geocoding\n",
            "   - extract_intent_and_select_metrics: SUCCESS - Extracted intent, selected 7 metrics\n",
            "   - geocode_location: SUCCESS - Geocoded to (12.9116225, 77.6388622)\n",
            "   - fetch_osm_data: SUCCESS - Fetched 25 POI categories\n",
            "   - calculate_statistics: SUCCESS - Calculated 7 metrics\n",
            "   - generate_summary: SUCCESS - Summary generated\n",
            "\n",
            "‚ö†Ô∏è  Warnings:\n",
            "   - Road density calculation not yet implemented\n",
            "   - Road density calculation not yet implemented\n"
          ]
        }
      ],
      "source": [
        "test4_state = create_initial_state(\n",
        "    user_input=\"HSR Layout, Bangalore\",\n",
        "    user_profile=\"Senior Citizen\"\n",
        ")\n",
        "\n",
        "result4 = run_test(graph, test4_state, \"Test 4: Full State Inspection\")\n",
        "\n",
        "if result4[\"success\"]:\n",
        "    final_state = result4[\"final_state\"]\n",
        "    \n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"üîç COMPLETE STATE INSPECTION\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    print(f\"\\nüì• Input:\")\n",
        "    print(f\"   - User Input: {final_state.get('user_input')}\")\n",
        "    print(f\"   - User Profile: {final_state.get('user_profile')}\")\n",
        "    \n",
        "    print(f\"\\nüåç Geocoding:\")\n",
        "    print(f\"   - Coordinates: {final_state.get('coordinates')}\")\n",
        "    print(f\"   - Address: {final_state.get('address')}\")\n",
        "    \n",
        "    print(f\"\\nüéØ User Intent:\")\n",
        "    intent = final_state.get('user_intent', {})\n",
        "    pprint(intent, width=80)\n",
        "    \n",
        "    print(f\"\\nüìä Selected Metrics ({len(final_state.get('selected_metrics', []))}):\")\n",
        "    for metric in final_state.get('selected_metrics', []):\n",
        "        print(f\"   - {metric}\")\n",
        "    \n",
        "    print(f\"\\nüìà Statistics ({len(final_state.get('statistics', {}))}):\")\n",
        "    stats = final_state.get('statistics', {})\n",
        "    for key, value in list(stats.items())[:10]:\n",
        "        print(f\"   - {key}: {value}\")\n",
        "    if len(stats) > 10:\n",
        "        print(f\"   ... and {len(stats) - 10} more\")\n",
        "    \n",
        "    print(f\"\\nüìù Summary:\")\n",
        "    summary = final_state.get('summary', 'N/A')\n",
        "    if summary and summary != 'N/A':\n",
        "        print(summary[:300] + \"...\" if len(summary) > 300 else summary)\n",
        "    else:\n",
        "        print(\"   No summary generated\")\n",
        "    \n",
        "    print(f\"\\nüìã Processing Steps ({len(final_state.get('processing_steps', []))}):\")\n",
        "    for step in final_state.get('processing_steps', []):\n",
        "        print(f\"   - {step}\")\n",
        "    \n",
        "    if final_state.get('errors'):\n",
        "        print(f\"\\n‚ùå Errors:\")\n",
        "        for error in final_state.get('errors', []):\n",
        "            print(f\"   - {error}\")\n",
        "    \n",
        "    if final_state.get('warnings'):\n",
        "        print(f\"\\n‚ö†Ô∏è  Warnings:\")\n",
        "        for warning in final_state.get('warnings', []):\n",
        "            print(f\"   - {warning}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test 5: Edge Cases\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "TEST: Test 5a: No Profile (Defaults)\n",
            "============================================================\n",
            "  ‚úì validate_input: validate_input: SUCCESS - Address detected, needs geocoding\n",
            "  ‚úì extract_intent_and_select_metrics: extract_intent_and_select_metrics: SKIPPED - No profile, used defaults\n",
            "  ‚úì geocode_location: geocode_location: SUCCESS - Geocoded to (12.9755264, 77.6067902)\n",
            "  ‚úì fetch_osm_data: fetch_osm_data: SUCCESS - Fetched 25 POI categories\n",
            "  ‚úì calculate_statistics: calculate_statistics: SUCCESS - Calculated 7 metrics\n",
            "  ‚úì generate_summary: generate_summary: SUCCESS - Summary generated\n",
            "\n",
            "‚úÖ TEST PASSED\n",
            "‚è±Ô∏è  Time: 12.59s\n",
            "\n",
            "============================================================\n",
            "TEST: Test 5b: Empty Input\n",
            "============================================================\n",
            "  ‚úì validate_input: validate_input: FAILED - No input provided\n",
            "  ‚úì handle_error: handle_error: Error handling completed\n",
            "\n",
            "‚úÖ TEST PASSED\n",
            "‚è±Ô∏è  Time: 0.00s\n",
            "\n",
            "‚ö†Ô∏è  Errors: 2\n",
            "   - User input is required\n",
            "   - User input is required\n",
            "\n",
            "============================================================\n",
            "TEST: Test 5c: Custom Free-Text Profile\n",
            "============================================================\n",
            "  ‚úì validate_input: validate_input: SUCCESS - Address detected, needs geocoding\n",
            "  ‚úì extract_intent_and_select_metrics: extract_intent_and_select_metrics: SUCCESS - Extracted intent, selected 7 metrics\n",
            "  ‚úì geocode_location: geocode_location: SUCCESS - Geocoded to (12.9292731, 77.5824229)\n",
            "  ‚úì fetch_osm_data: fetch_osm_data: SUCCESS - Fetched 25 POI categories\n",
            "  ‚úì calculate_statistics: calculate_statistics: SUCCESS - Calculated 7 metrics\n",
            "  ‚úì generate_summary: generate_summary: SUCCESS - Summary generated\n",
            "\n",
            "‚úÖ TEST PASSED\n",
            "‚è±Ô∏è  Time: 15.57s\n",
            "\n",
            "‚ö†Ô∏è  Warnings: 2\n",
            "   - Road density calculation not yet implemented\n",
            "   - Road density calculation not yet implemented\n",
            "\n",
            "üìä Final State Summary:\n",
            "   - Coordinates: (12.9292731, 77.5824229)\n",
            "   - Address: Jayanagar, Tilak Nagara, Bengaluru South City Corporation, Bengaluru, Bangalore South, Bengaluru Urban, Karnataka, 560011, India\n",
            "   - Selected Metrics: 7\n",
            "   - Statistics Count: 7\n",
            "   - Summary Generated: True\n",
            "   - User Intent: {'profile_type': 'fitness enthusiast', 'priorities': ['gyms', 'parks', 'connectivity'], 'concerns': ['safety'], 'lifestyle': 'Active, social lifestyle', 'metric_selection_reasoning': 'Selected metrics based on user priorities for gyms, parks, and connectivity'}\n",
            "\n",
            "üéØ Extracted Intent:\n",
            "   - Profile Type: fitness enthusiast\n",
            "   - Priorities: ['gyms', 'parks', 'connectivity']\n",
            "\n",
            "üìä Selected Metrics:\n",
            "   ‚úÖ Found fitness-related metrics: ['park_area_km2', 'gym_fitness_count']\n",
            "   All metrics: ['park_area_km2', 'gym_fitness_count', 'metro_station_count', 'bus_stop_count', 'road_density_km_per_km2', 'walkability_score', 'poi_density']\n"
          ]
        }
      ],
      "source": [
        "# Test 5a: No Profile\n",
        "test5a_state = create_initial_state(\n",
        "    user_input=\"MG Road, Bangalore\",\n",
        "    user_profile=None\n",
        ")\n",
        "\n",
        "result5a = run_test(graph, test5a_state, \"Test 5a: No Profile (Defaults)\")\n",
        "print_test_results(result5a, verbose=False)\n",
        "\n",
        "# Test 5b: Empty Input\n",
        "test5b_state = create_initial_state(\n",
        "    user_input=\"\",\n",
        "    user_profile=\"Bachelor\"\n",
        ")\n",
        "\n",
        "result5b = run_test(graph, test5b_state, \"Test 5b: Empty Input\")\n",
        "print_test_results(result5b, verbose=False)\n",
        "\n",
        "# Test 5c: Custom Free-Text Profile\n",
        "test5c_state = create_initial_state(\n",
        "    user_input=\"Jayanagar, Bangalore\",\n",
        "    user_profile=\"I'm a fitness enthusiast who loves parks and gyms, need good connectivity\"\n",
        ")\n",
        "\n",
        "result5c = run_test(graph, test5c_state, \"Test 5c: Custom Free-Text Profile\")\n",
        "print_test_results(result5c, verbose=True)\n",
        "\n",
        "if result5c[\"success\"]:\n",
        "    intent = result5c[\"final_state\"].get(\"user_intent\", {})\n",
        "    selected = result5c[\"final_state\"].get(\"selected_metrics\", [])\n",
        "    \n",
        "    print(f\"\\nüéØ Extracted Intent:\")\n",
        "    print(f\"   - Profile Type: {intent.get('profile_type')}\")\n",
        "    print(f\"   - Priorities: {intent.get('priorities', [])}\")\n",
        "    \n",
        "    print(f\"\\nüìä Selected Metrics:\")\n",
        "    fitness_metrics = [m for m in selected if 'gym' in m.lower() or 'fitness' in m.lower() or 'park' in m.lower()]\n",
        "    if fitness_metrics:\n",
        "        print(f\"   ‚úÖ Found fitness-related metrics: {fitness_metrics}\")\n",
        "    print(f\"   All metrics: {selected}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary and Conclusions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "üìã TEST SUITE SUMMARY\n",
            "============================================================\n",
            "\n",
            "‚úÖ Passed: 5/5\n",
            "‚ùå Failed: 0/5\n",
            "\n",
            "‚è±Ô∏è  Average Execution Time: 17.85s\n",
            "\n",
            "üéØ Key Findings:\n",
            "   - Parallel execution: Intent extraction runs independently\n",
            "   - Profile handling: Works with categorical and free-text profiles\n",
            "   - Error handling: Gracefully handles invalid inputs\n",
            "   - Default fallback: Uses defaults when profile is missing\n",
            "   - Metrics selection: LLM selects relevant metrics based on intent\n",
            "\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "print(f\"\\n{'='*60}\")\n",
        "print(\"üìã TEST SUITE SUMMARY\")\n",
        "print(f\"{'='*60}\")\n",
        "\n",
        "# Collect all results\n",
        "all_results = []\n",
        "if 'result1' in locals() and result1.get(\"success\") is not None:\n",
        "    all_results.append(result1)\n",
        "if 'result2' in locals() and result2.get(\"success\") is not None:\n",
        "    all_results.append(result2)\n",
        "if 'result4' in locals() and result4.get(\"success\") is not None:\n",
        "    all_results.append(result4)\n",
        "if 'result5a' in locals() and result5a.get(\"success\") is not None:\n",
        "    all_results.append(result5a)\n",
        "if 'result5c' in locals() and result5c.get(\"success\") is not None:\n",
        "    all_results.append(result5c)\n",
        "\n",
        "if all_results:\n",
        "    passed = sum(1 for r in all_results if r.get(\"success\", False))\n",
        "    failed = len(all_results) - passed\n",
        "    \n",
        "    print(f\"\\n‚úÖ Passed: {passed}/{len(all_results)}\")\n",
        "    print(f\"‚ùå Failed: {failed}/{len(all_results)}\")\n",
        "    \n",
        "    if performance_results:\n",
        "        avg_time = sum(r[\"time\"] for r in performance_results) / len(performance_results)\n",
        "        print(f\"\\n‚è±Ô∏è  Average Execution Time: {avg_time:.2f}s\")\n",
        "    \n",
        "    print(f\"\\nüéØ Key Findings:\")\n",
        "    print(f\"   - Parallel execution: Intent extraction runs independently\")\n",
        "    print(f\"   - Profile handling: Works with categorical and free-text profiles\")\n",
        "    print(f\"   - Error handling: Gracefully handles invalid inputs\")\n",
        "    print(f\"   - Default fallback: Uses defaults when profile is missing\")\n",
        "    print(f\"   - Metrics selection: LLM selects relevant metrics based on intent\")\n",
        "    \n",
        "    print(f\"\\n{'='*60}\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è  No test results available. Run the test cells above first.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
